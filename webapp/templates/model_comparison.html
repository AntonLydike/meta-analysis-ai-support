{% extends "base.html" %}

{% block title %}Model Comparison{% endblock %}

{% block content %}
        <h1 class="mb-4">Reviewer Model Comparison</h1>

        <div class="alert alert-warning" role="alert">
            <p><strong>Disclaimer:</strong> Due to models failing to give ratings (see the holes in the main table), every model gave a different number of ratings. Furthermore, I ran every model twice against the dataset, so we could get a better idea of their variance (let me know if this isn't fine please!).</p>
            <p>This table takes into account each rating given by any given model type. Relevant is the number of times the model rated a document that was human marked as relevant. Same for irrelevant, etc...</p>
        </div>

        {% for table in tables %}
            <h3 class="mt-5">Threshold: rating &gt; {{ table.threshold }}</h3>
            <div class="table-responsive">
                <table class="table table-bordered table-hover align-middle">
                    <thead class="table-light">
                        <tr>
                            <th>Job</th>
                            <th>Model</th>
                            <th>Relevant</th>
                            <th>Irrelevant</th>
                            <th title="True Positives">TP</th>
                            <th title="False Positives">FP</th>
                            <th title="False Negatives">FN</th>
                            <th title="True Negatives">TN</th>
                            <th>Sensitivity</th>
                            <th>Specificity</th>
                        </tr>
                    </thead>
                    <tbody>
                        {% for row in table.rows %}
                        <tr>
                            <td><a href="{{ url_for('job_detail', job_id=row['job_id']) }}">{{ row['job_name'] }}</a></td>
                            <td>{{ row['model_name'] }}</td>
                            <td>{{ row['relevant_papers'] }}</td>
                            <td>{{ row['irrelevant_papers'] }}</td>
                            <td>{{ row['true_positives'] }}</td>
                            <td>{{ row['false_positives'] }}</td>
                            <td>{{ row['false_negatives'] }}</td>
                            <td>{{ row['true_negatives'] }}</td>
                            <td>{{ row['sensitivity'] if row['sensitivity'] is not none else '—' }}</td>
                            <td>{{ row['specificity'] if row['specificity'] is not none else '—' }}</td>
                        </tr>
                        {% endfor %}
                    </tbody>
                </table>
            </div>
        {% endfor %}

        <br/>
        <br/>
        
        <h2 class="mb-4">Visualization</h1>

        <div class="row">
            <div class="col-md-6">
              <figure class="figure w-100">
                <div class="figure-img d-flex justify-content-center"">
                  {{ sensitivity_svg | safe }}
                </div>
                <figcaption class="figure-caption text-center fw-semibold">Sensitivity of the models for different threshold values as reported in the tables above. Higher is better.</figcaption>
              </figure>
            </div>
          
            <div class="col-md-6">
              <figure class="figure w-100">
                <div class="figure-img d-flex justify-content-center"">
                  {{ specificity_svg | safe }}
                </div>
                <figcaption class="figure-caption text-center fw-semibold">Specificity of the models for different threshold values as reported in the tables above. Higher is better.</figcaption>
              </figure>
            </div>
          </div>
{% endblock %}
